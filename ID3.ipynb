{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementy sztucznej inteligencji\n",
    "# Projekt: Binarne Drzewa Decyzyjne\n",
    "autorzy:\n",
    "1. Arkadiusz Florek\n",
    "2. Maciej Komosa\n",
    "3. Albert Pieniądz\n",
    "4. Jakub Zięba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, math as mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcje do obliczania entropii dla danej konkluzji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prawdopodobienstwo(wartosci, konkluzje, nr_konkluzji):\n",
    "\n",
    "    nr_konkluzji += 1\n",
    "    # tabela zawierająca unikatowe wartości z tabeli wartości\n",
    "    unikatowe = list(set(wartosci))\n",
    "\n",
    "    wartosci = wartosci[konkluzje == nr_konkluzji]\n",
    "    \n",
    "    # tabela zawierająca częstości wystąpienia poszczególnych wartości przesłanek\n",
    "    p_tab = np.array([0] * len(unikatowe))\n",
    "\n",
    "    # pętla iterująca po tabeli unikatowe\n",
    "    for i in range(len(unikatowe)):\n",
    "        # pętla iterująca po tabeli wartości\n",
    "        for j in range (len(wartosci)):\n",
    "            # dla wartości równej wartości unikatowej dodajemy do częstości 1\n",
    "            if wartosci[j] == unikatowe[i]:\n",
    "                p_tab[i] += 1\n",
    "    \n",
    "    # dzielimy tabelę częstości na ilość wszystkich wartości\n",
    "    p_tab = p_tab / len(wartosci)\n",
    "    return p_tab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia(p_tab):\n",
    "    I = 0\n",
    "    for p in p_tab:\n",
    "        if p == 0:\n",
    "            continue\n",
    "        else:\n",
    "            I += -p*mat.log2(p)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def przyrost_informacji(self, wartosci, nr_przeslanki):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa węzła"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wezel:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.value = None\n",
    "        self.next = None\n",
    "        self.childs = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sport.csv\")\n",
    "data.head()\n",
    "X = data.iloc[:, 0:-1]\n",
    "Y = data.iloc[:, -1]\n",
    "\n",
    "p_tab = []; p_buf = []\n",
    "e_tab = []; e_buf = []\n",
    "\n",
    "for przeslanka in range(X.shape[1]):\n",
    "    for konkluzja in range(len(set(Y))):\n",
    "        p_buf.append(prawdopodobienstwo(X.iloc[:, przeslanka].to_numpy(), Y, konkluzja))\n",
    "        e_buf.append(entropia(p_buf[-1]))\n",
    "    p_tab.append(p_buf)\n",
    "    e_tab.append(e_buf)\n",
    "    p_buf = []; e_buf = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
